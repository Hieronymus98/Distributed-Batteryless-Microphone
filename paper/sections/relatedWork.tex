\subsection{Energy-harvesting}

Ambient energy is volatile, and scarce. For example, radio waves harvestable power varies from \si{\nano\watt}-scale when harvesting ambient RF energy to \si{\uW}-scale when harvesting a dedicated RF signal; and solar power ranges from tens of \si{\uW} to tens of \si{\mW} when it is harvested by a solar panels of a few \si{\cm^2} illumination surface~\cite{lucia2017intermittent,rao2017ambient}.%Mechanical harvesters deliver power on a scale ranges from \si{\nW} to \si{\W} depending on the used harvester, i.e. buttons, sliders, or knobs~\cite{} 

A tiny energy-harvesting device slowly charges its energy buffer (e.g. capacitor) while the device is off. Once the buffer is full, the device begins operating and depleting its energy reservoir---since power consumption is much higher than harvested power---until it powers down. This charging-discharging cycle repeats indefinitely (Figure~\ref{fig:powerCycle}). 

Many batteryless energy-harvesting platforms have been proposed, for example Wireless Identification and Sensing Platform (WISP)~\cite{smith_ubicomp_2006} and its variants such as NFC-WISP~\cite{zhao2015nfc}, WISPcam~\cite{naderiparizi_rfid_2015}, and NeuralWISP~\cite{yeager2009neuralwisp}, batteryless phone~\cite{talla2017battery}, ambient backscatter tag~\cite{liu2013ambient} and Moo~\cite{moo}.

\subsection{Intermittent execution}
\todo{brought from introduction}Mementos~\cite{mementos}proposed a
Checkpointing-based approach to enable long-running applications on intermittently-powered devices. DINO~\cite{dino}enables safe non-volatile memory access despite power failures. Chain~\cite{colin2016chain} minimizes the amount of data need to be protected by introducing the concepts of atomic tasks and data-channels. Alpaca and Ratchet~\cite{maeng2017alpaca,woude2016ratchet} use compilers to automate intermittent code generation. Mayfly~\cite{hester2017timerly} enables time-aware intermittent computing. InK~\cite{yildirim2018ink} introduces event-driven intermittent execution.

% What is the problem that requires intermittent execution
Intermittent execution models~\cite{van2016intermittent,colin2016chain,lucia2015simpler,bhatti2017harvos} enable applications to progress despite frequent power failure. They decompose an application into several small code pieces and save the progress state of the application on the transitions between these code segments. Therefore, intermittent applications do not return to the same execution point (e.g. \texttt{main()}) after each power failure, as the applications that assume continuous power supply, instead they resume from the last saved progress state of execution.   
% Sleep not to die 
Intermittent systems are regarded as the successor of energy-aware systems. Dewdrop~\cite{buettner2011dewdrop} is an energy-aware runtime for (Computational) RFIDs such as WISP. 
Dewdrop goes into low-power mode until sufficient energy for a given task is accumulated. QuarkOS~\cite{zhang2013quarkos} divides the given task (i.e. sending a message) into small segments and sleeps after finishing a segment for charging energy. However, these systems are not disruption tolerance.  
% checkpointing 

The first power-failure-tolerant systems use the idea of volatile progress state checkpointing into persistent memory~\cite{mementos}. DINO~\cite{dino}, however, shows that in addition to the volatile memory, the non-volatile memory of the processor must also be protected to ensure correct executions. Hibernus~\cite{balsamo2015hibernus} measures the voltage level in the energy buffer to reduce the number of checkpoints. Ratchet~\cite{woude2016ratchet} uses compiler analysis to eliminate the need of programmer intervention or hardware support. HarvOS~\cite{bhatti2017harvos} uses both compiler and hardware support to optimize checkpoint placement and energy consumption.

% task-based
Task-based systems optimize intermittent execution by reducing the amount of data needed to be saved into non-volatile memory to protect applications against power interruptions~\cite{colin2016chain}. However,  
% I/O and time related

% languages

% debugging 

\subsection{Speech recognition}
The speech recognition problem has been tackled from many angles and has experienced many great breakthroughs. For example, Dynamic time warping (DTW) algorithm enables matching voice signals with different speed (or time) \cite{}. Approaches based on Hidden Markov Models showed much better performance than DTW-based ones~\cite{jelinek1997statistical}. Hence, they became the standard techniques for general purpose speech recognition until artificial intelligent algorithms~\cite{hinton2012deep}, however, outperform them. 

Many specialized hardware architectures for speech recognition have been proposed to, for instance, reduce energy consumption \cite{price2018low,price20156}. 

Speech recognition algorithms can be classified based on the type of speech that they can recognize into: \textit{spontaneous speech, continuous speech, connected word,} and \textit{isolated word}~\cite{gaikwad2010review}.

Systems with \textit{continuous} or \textit{spontaneous speech} recognition are the closest to natural speech, but are the most difficult to create because they need special methods to detect word boundaries~\cite{gaikwad2010review}. This is less the case for the \textit{connected word} type, where a minimum pause between the words is required.
 The type with the least complexity is the \textit{isolated word} type. It requires a period of silence on both sides of a spoken word and accepts only single words. 

Speech recognition consists of several steps. The basic steps are mentioned briefly here:
\textit{Speech recording and signal digitization}---a microphone records the sound waves and an ADC converts the microphone signal into a digital signal. A sampling rate of about 8 kHz is required to capture the frequencies of a human voice (100-4000Hz \cite{Bernal-Ruiz2005}). \textit{Framing}---after that the digitized signal is divided into blocks of usually 10-30 ms~\cite{gaikwad2010review,delaney2002low,delaney2005energy} called frames. \textit{Features extraction}---for each frame a feature vector is extracted containing all the relevant acoustic information. \textit{Feature matching}---finally the extracted features are matched against features known to the recognizer. 

